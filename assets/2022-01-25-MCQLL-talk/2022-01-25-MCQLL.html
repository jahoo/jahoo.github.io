<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-99.9.9">
  <meta name="author" content="Jacob Louis Hoover">
  <meta name="dcterms.date" content="2022-01-25">
  <title>Processing time vs.&nbsp;surprisal</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="2022-01-25-MCQLL_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="2022-01-25-MCQLL_files/libs/revealjs/dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <link rel="stylesheet" href="2022-01-25-MCQLL_files/libs/revealjs/dist/theme/quarto.css" id="theme">

  <script defer="" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
  <script src="2022-01-25-MCQLL_files/libs/clipboard/clipboard.min.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/quarto-html/tabby.min.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/quarto-html/popper.min.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/quarto-html/tippy.umd.min.js"></script>
  <link href="2022-01-25-MCQLL_files/libs/quarto-html/tippy.css" rel="stylesheet">
  <link href="2022-01-25-MCQLL_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet">
  <link href="2022-01-25-MCQLL_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet">
  <link href="2022-01-25-MCQLL_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="2022-01-25-MCQLL_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="2022-01-25-MCQLL_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="2022-01-25-MCQLL_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.7em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > :last-child,
  .callout.callout-captioned .callout-body > div > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal #title-slide.center,
    .reveal .title-slide.center,
    .reveal .controls .navigate-left .controls-arrow,
    .reveal .controls .navigate-right .controls-arrow {
      margin-top: -15px;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section class="center">
  <h1 class="title">Processing time vs.&nbsp;surprisal</h1>
  <p class="subtitle">with better language models, the relationship is superlinear</p>
  <p class="author">Jacob Louis Hoover</p>
  <p class="institute">MCQLL</p>
  <p class="date">25 Jan 2022</p>
</section>

<section>
<section class="title-slide slide level1 center">
<h1>1: Background</h1>
<p>Human processing time and predictability</p>
</section>
<section class="slide level2">
<h2></h2>
<h3>Processing time is related to incremental predictability.</h3>
<div>
<ul>
<li class="fragment">General relationship: less predictable words take more time to process <span class="citation" data-cites="ehrlich.s:1981 balota.d:1985">(e.g. <a href="#/ref-ehrlich.s:1981" role="doc-biblioref" onclick="return false;">Ehrlich and Rayner 1981</a>; <a href="#/ref-balota.d:1985" role="doc-biblioref" onclick="return false;">Balota et al. 1985</a>)</span>. We can write: <span class="math display">\text{cost}(w) = f( p(w | \text{context}))</span></li>
<li class="fragment">What is linking function, <span class="math inline">f</span>? Influential “surprisal theory” <span class="citation" data-cites="hale.j:2001 levy.r:2005 levy.r:2008 smith.n:2013">(<a href="#/ref-hale.j:2001" role="doc-biblioref" onclick="return false;">Hale 2001</a>; <a href="#/ref-levy.r:2005" role="doc-biblioref" onclick="return false;">Levy 2005</a>, <a href="#/ref-levy.r:2008" role="doc-biblioref" onclick="return false;">2008</a>; <a href="#/ref-smith.n:2013" role="doc-biblioref" onclick="return false;">Smith and Levy 2013</a>)</span> proposes cost is <strong>linear in surprisal</strong>: <span class="math display">\text{cost}(w) \propto  -\log p(w | \text{context}) \triangleq \mathrm{surp}(w)</span></li>
</ul>
</div>
</section>
<section class="slide level2">
<h2>Surprisal theory</h2>
<p>Empirical studies</p>
<div class="columns onlytextwidth" data-align="bottom">
<div class="column">
<p>response: <strong>human processing cost</strong>:</p>
<ul>
<li>gaze duration</li>
<li>self-paced reading time <!-- - also N400 --></li>
</ul>
</div><div class="column">
<p>predictor: <strong>incremental surprisal</strong>:</p>
<ul>
<li>from language models <!-- - also "cloze" task estimates --></li>
</ul>
</div>
</div>
<div class="fragment">
<p>Using 3-gram surprisal estimates <span class="citation" data-cites="smith.n:2013">(<a href="#/ref-smith.n:2013" role="doc-biblioref" onclick="return false;">Smith and Levy 2013</a>)</span>:</p>
<p><img data-src="overview-figs/smith.n.2013-figb2.png" class="fragment" height="350"></p>
</div>
<div class="fragment">
<p>Looks linear.</p>
</div>
</section>
<section class="slide level2">

<p><span class="citation" data-cites="smith.n:2013">Smith and Levy (<a href="#/ref-smith.n:2013" role="doc-biblioref" onclick="return false;">2013</a>)</span> used (then state-of-the-art) 3-gram language models.</p>
<ul>
<li>careful study; found linear relationship</li>
</ul>

<img data-src="img_external/smith.j.2013-fig1.jpg" class="r-stretch quarto-figure-center"><p class="caption"><span class="citation" data-cites="smith.n:2013">Smith and Levy (<a href="#/ref-smith.n:2013" role="doc-biblioref" onclick="return false;">2013, fig. 1</a>)</span></p><div class="fragment">
<p>Following literature has introduced newer language models (larger n-grams, LSTM, Transformer-based)</p>
<ul>
<li>a number of studies assume linear relationship <span class="citation" data-cites="aurnhammer.c:2019cogsci">(e.g. <a href="#/ref-aurnhammer.c:2019cogsci" role="doc-biblioref" onclick="return false;">Aurnhammer and Frank 2019</a>)</span>, and use Linear Mixed Effects (LME) models</li>
<li>find evidence of a (near-)linear relationship <span class="citation" data-cites="goodkind.a:2018 boyce.v:2020amlap wilcox.e:2020">(<a href="#/ref-goodkind.a:2018" role="doc-biblioref" onclick="return false;">Goodkind and Bicknell 2018</a>; <a href="#/ref-wilcox.e:2020" role="doc-biblioref" onclick="return false;">Wilcox et al. 2020</a>; <a href="#/ref-boyce.v:2020amlap" role="doc-biblioref" onclick="return false;">Boyce and Levy 2020</a>)</span>
<ul>
<li>also use LME for analysis</li>
</ul></li>
<li>the better the language models, the better the fit (<strong>predictive power</strong>)</li>
</ul>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>However</h1>
<p>Reasons to question the conclusion that processing linear in surprisal</p>
<ul>
<li>theoretical</li>
<li>empirical</li>
</ul>
</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Theoretical reasons</h2>
<p>Surprisal theory is motivated by a <em>computational</em> level argument.</p>
<div class="fragment">
<div style="padding: 1rem; border: thick solid; border-radius: 12px;">
<p>“Highly-incremental processing” argument outline:</p>
<div>
<ul>
<li class="fragment">suppose there is function <span class="math inline">f:</span> predictability <span class="math inline">\to</span> processing cost</li>
<li class="fragment">some item’s probability <span class="math inline">p = p_1 p_2 \cdots p_n</span></li>
<li class="fragment">item’s cost <span class="math inline">f(p) = f( p_1 p_2 \cdots p_n ) = f( p_1 ) + f( p_2 ) + \ldots f( p_n )</span></li>
<li class="fragment"><span class="math inline">\implies f</span> is logarithmic. That is, cost is linear in surprisal.</li>
</ul>
</div>
</div>
</div>
<div class="fragment">
<p><br></p>
<p>But, how is this accomplished? No associated <em>algorithmic</em> level theory.</p>
</div>
<div class="fragment">
<ul>
<li><p>What processing algorithm has runtime that is linear in surprisal?</p></li>
<li><p>… first question: what algorithms can depend on probability?</p></li>
</ul>
</div>
<div class="fragment">
<p><strong>Sampling-based algorithms</strong></p>
<aside class="notes">
<p>Note: normally we look at algorithm complexity in some parameter, space or time. Here parameter is probability.</p>
<p>Not many algorithms have been studied from this perspective. Algorithms that do exact inference don’t depend on probability at all.</p>
</aside>
</div>
</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<h3>Processing as sampling</h3>
<p><strong>Sampling-based algorithms</strong></p>
<p>Idea:</p>
<div>
<ul>
<li class="fragment">Distribution <span class="math display">p(\cdot\mid w_{1:n})</span> of current hypotheses about complete structure conditioned on the partial input (<span class="math inline">n</span> observed words).</li>
<li class="fragment">Processing model comprises of algorithm for sampling from this distribution</li>
<li class="fragment">Runtime of this sampler (<strong>how long it takes to successfully sample</strong>) would be a natural predictability-based model of processing difficulty</li>
</ul>
</div>
<div class="fragment">
<p>Sampling-based processing <span class="math inline">\implies</span> cost exponential in surprisal</p>
<aside class="notes">
<p>Intuitively, expect that it will be harder to sample when conditioning on unlikely/surprising observation</p>
</aside>
</div>
</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<h3>Processing as sampling</h3>
<p>Sampling-based processing <span class="math inline">\implies</span> cost exponential in surprisal</p>
<div class="fragment">
<div style="padding: 1rem; border: thick solid; border-radius: 12px;">
<div>
<ol type="1">
<li class="fragment"><p><strong>Incremental surprisal is a KL</strong></p>
<p>Relative entropy of distribution before vs after seeing the next word precisely the incremental surprisal <span class="citation" data-cites="levy.r:2008">(<a href="#/ref-levy.r:2008" role="doc-biblioref" onclick="return false;">Levy 2008, sec. 2.1</a>)</span> <span class="math display">\mathrm{KL}( p(\cdot\mid w_{1:n+1})  \parallel  p(\cdot\mid w_{1:n})) = -\log p(w_{n+1} \mid w_{1:n})</span></p></li>
<li class="fragment"><p><strong>Expected sampling runtime is exponential in KL</strong></p>
<p>runtime for a sampling conditional distribution exponential in KL <span class="math display">\text{expected sampling runtime}
  \approx e^{[\mathrm{KL}( p(\cdot\mid w_{1:n+1})
  \parallel  p(\cdot\mid w_{1:n})]}</span></p>
<ul>
<li class="fragment">straightforward proof for rejection sampling <span class="citation" data-cites="freer.f:2010">(e.g. <a href="#/ref-freer.f:2010" role="doc-biblioref" onclick="return false;">Freer et al. 2010</a>)</span>.</li>
<li class="fragment">importance sampling <span class="citation" data-cites="chatterjee.s:2017">(<a href="#/ref-chatterjee.s:2017" role="doc-biblioref" onclick="return false;">Chatterjee and Diaconis 2017</a>)</span>.</li>
</ul></li>
</ol>
</div>
</div>
<aside class="notes">
<ul>
<li>Note a: these distributions are both over structures for the complete sentence.</li>
<li>Note b: general is this result?</li>
</ul>
</aside>
</div>
<div class="fragment">
<p>Exponential is definitely superlinear.</p>
</div>
</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<h3>Processing as sampling</h3>
<p>Surprisal theory predicts cost is <strong>linear</strong> in surprisal.</p>
<p>Sampling-based processing <span class="math inline">\implies</span> cost <strong>exponential</strong> in surprisal</p>
<div class="fragment">
<ul>
<li><p>We don’t know of an algorithm where runtime scales linearly in surprisal.</p></li>
<li><p>Reason to ask: <em>Is the empirical relationship between surprisal and processing cost superlinear?</em></p></li>
</ul>
</div>
</section>
<section class="slide level2">
<h2>Empirical reasons</h2>
<p>Recent studies give reasons to question strictly linear linking function.</p>
<ul>
<li><span class="citation" data-cites="schijndel.m:2018">Schijndel and Linzen (<a href="#/ref-schijndel.m:2018" role="doc-biblioref" onclick="return false;">2018</a>)</span> examine garden path effects, and find
<ul>
<li>a linear linking function can’t predict the magnitude of human increase in processing.</li>
</ul></li>
<li>In context of motivating uniform density hypothesis, <span class="citation" data-cites="meister.c:2021">Meister et al. (<a href="#/ref-meister.c:2021" role="doc-biblioref" onclick="return false;">2021</a>)</span> examine whether nonlinear linking function may give better fit than linear.
<ul>
<li>Using surprisal estimates from state-of-the-art Transformer-based language models, suggest superlinear shaped linking function.</li>
</ul></li>
</ul>
</section>
<section class="slide level2">
<h2>Motivates a new study</h2>
<p>Given reasons to reconsider linear linking function:</p>
<p><strong>Theoretical</strong>: Lack of algorithmic theory of processing which is capable predicting of linear linking function</p>
<ul>
<li>sampling algorithms are superlinear</li>
</ul>
<p><strong>Empirical</strong>: Recent evidence suggesting superlinear linking function.</p>
<p><br> <strong>What is needed:</strong></p>
<p>a study</p>
<ul>
<li>directly asking whether linking function is nonlinear</li>
<li>using modern state-of-the-art language models</li>
</ul>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>2: Methods</h1>
<p>We want to revisit question of linking function.</p>
<ul>
<li>specifically: can we actually assume function is linear?</li>
</ul>
<p>What tools do we have?</p>
</section>
<section class="slide level2">
<h2>GAMs!</h2>
<p>We fit penalized regression splines using <em>generalized additive models</em> (GAMs).</p>
<div class="fragment">
<p>Motivation:</p>
<ul>
<li><ol type="1">
<li>they are the tool for the job</li>
</ol>
<ul>
<li>don’t want to assume any particular parametric form (linear)</li>
<li>want an interpretable regression model, like LME</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<ul>
<li><ol start="2" type="1">
<li>previous literature also use these models</li>
</ol>
<ul>
<li><span class="citation" data-cites="goodkind.a:2018">Goodkind and Bicknell (<a href="#/ref-goodkind.a:2018" role="doc-biblioref" onclick="return false;">2018</a>)</span>; <span class="citation" data-cites="boyce.v:2020amlap">Boyce and Levy (<a href="#/ref-boyce.v:2020amlap" role="doc-biblioref" onclick="return false;">2020</a>)</span>; <span class="citation" data-cites="wilcox.e:2020">Wilcox et al. (<a href="#/ref-wilcox.e:2020" role="doc-biblioref" onclick="return false;">2020</a>)</span>; all following <span class="citation" data-cites="smith.n:2013">Smith and Levy (<a href="#/ref-smith.n:2013" role="doc-biblioref" onclick="return false;">2013</a>)</span></li>
<li>often use GAMs to qualitatively confirm relationship.</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<p>Our study is different</p>
<ul>
<li><p>use GAMs to explicitly compare linear and nonlinear fit, rather than as tool to verify qualitatively that relationship is ‘near-linear’ <span class="citation" data-cites="wilcox.e:2020">(<a href="#/ref-wilcox.e:2020" role="doc-biblioref" onclick="return false;">Wilcox et al. 2020</a>)</span></p></li>
<li><p>choices in specifying GAMs</p></li>
</ul>
</div>
</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">GAMs?</h2>
<p>Well-studied, flexible, interpretable tool for nonparametric regression.</p>
<div class="fragment">
<p>Middle ground: Linear models — <strong>GAMs</strong> — black-box ML</p>

<p><span class="math display">\underbrace{\text{penalize underfit}}_\text{maximize lik/minimize err} \quad\text{and}\quad\underbrace{\text{penalize overfit}}_\text{minimize wiggliness}
</span></p>
</div>
<img data-src="motivatingGams/gamsRmd-fitting-data.png" class="r-stretch"></section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">GAMs?</h2>
<p><span class="math display">\underbrace{\text{penalize underfit}}_\text{maximize lik/minimize err} \quad\text{and}\quad\underbrace{\text{penalize overfit}}_\text{minimize wiggliness}
</span></p>
<p><span class="math display">
\hat \theta = \arg\min_\theta \{
\overbrace{||\mathbf{y} - \mathbf{f}_\theta||^2} + \overbrace{\lambda\times\text{wiggliness}(f_\theta)}
\}</span></p>
<p><span class="math display">\mathbf{f}_\theta = (
f_\theta(\mathbf{x_1}),f_\theta(\mathbf{x_2})\ldots,f_\theta(\mathbf{x_N})
)^T</span></p>
<div class="fragment">
<p>Wigglinness penalty, for instance, <span class="math inline">\text{wiggliness}(f_\theta)= \int \left( \textstyle\frac{\mathrm{d}^n}{{\mathrm{d}}x^n}f_\theta(x) \right)^2 \mathrm{d}x</span></p>
<p>Penalty <em>null space</em> (functions not penalized): <span class="math inline">n=2 \implies</span> linear functions</p>
</div>
<div class="fragment">
<p>Fitting a GAM:</p>
<ol type="1">
<li>for fixed <span class="math inline">\lambda</span>, fit model to maximize likelihood/minimize error</li>
<li>fit <span class="math inline">\lambda</span> by e.g.&nbsp;cross validation</li>
</ol>
</div>
</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">GAMs?</h2>
<p>Fitting a GAM:</p>
<ol type="1">
<li>for fixed <span class="math inline">\lambda</span>, fit model to maximize likelihood/minimize error</li>
<li>fit <span class="math inline">\lambda</span> by e.g.&nbsp;cross validation</li>
</ol>

<img data-src="motivatingGams/gamsRmd-fitting-smoothing.png" class="r-stretch"></section>
<section class="slide level2">
<h2>Bases</h2>
<p>How to fit? Represent <span class="math inline">f_\theta(x) = \sum_{i} \theta_i b_i(x)</span></p>
<div class="panel-tabset fragment" data-fragment-index="1">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Cubic polynomial splines</a></li><li><a href="#tabset-1-2">Thin plate splines</a></li></ul>
<div class="tab-content" data-fragment-index="1">
<div id="tabset-1-1">
<p>Basis for piecewise cubic functions, between “knots”.</p>
<p><img data-src="motivatingGams/gamsRmd-fitting-cr_k10.png"> <img data-src="motivatingGams/gamsRmd-fitting-cr_k10.gif" class="fragment" data-fragment-index="2" style="width:100.0%"> <img data-src="motivatingGams/gamsRmd-fitting-cr_k20.png"> <img data-src="motivatingGams/gamsRmd-fitting-cr_k20.gif" class="fragment" data-fragment-index="2" style="width:100.0%"></p>
<!-- ### Cubic B-splines

Basis for piecewise polynomial functions, between "knots".

![](motivatingGams/gamsRmd-fitting-bs.png)
![](motivatingGams/gamsRmd-fitting-bs.gif){.fragment width=100% fragment-index=2}

![](motivatingGams/gamsRmd-Bsplines.png){.fragment width=100% fragment-index=2}
 -->
</div>
<div id="tabset-1-2">
<p>General solution to minimize <span class="math inline">||\mathbf{y} - \mathbf{f}_\theta||^2 + \lambda\times J_{md}(f_\theta)</span></p>
<p>Does not require knots. Thin plate regressions splines (TPRS) is low-rank approximation.</p>
<p><img data-src="motivatingGams/gamsRmd-fitting-tp_k6.png"> <img data-src="motivatingGams/gamsRmd-fitting-tp_k6.gif" class="fragment" data-fragment-index="2" style="width:100.0%"> <img data-src="motivatingGams/gamsRmd-fitting-tp_k20.png"> <img data-src="motivatingGams/gamsRmd-fitting-tp_k20.gif" class="fragment" data-fragment-index="2" style="width:100.0%"></p>
</div>
</div>
</div>
</section>
<section class="slide level2">
<h2>GAM theory</h2>
<p>A GAM is just GLM but replace <em>linear predictor</em> with <em>smooth function</em>.</p>
<ul>
<li>smooth is a linear combination of basis functions.</li>
<li>fit by penalized estimation, minimize loss = error + penalty</li>
</ul>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">LM</a></li><li><a href="#tabset-2-2">LMM</a></li><li><a href="#tabset-2-3">GLM</a></li><li><a href="#tabset-2-4">GAM</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<p><span class="math display">\mu = \beta_0 + \beta_1 x\\
y \sim \mathcal{N}(\mu,\sigma^2)</span></p>
</div>
<div id="tabset-2-2">
<p><span class="math display">\mu = \beta_0 + \beta_1 x + \gamma z\\
y \sim \mathcal{N}(\mu,\sigma^2)</span></p>
<p><span class="math display">\gamma \sim \mathcal{N}(\mu,\sigma^2_z)</span></p>
</div>
<div id="tabset-2-3">
<p><span class="math display">g(\mu) = \beta_0 + \beta_1 x\\
y \sim \mathrm{EF}(\mu,\phi)</span></p>
</div>
<div id="tabset-2-4">
<p><span class="math display">g(\mu) = f(x)\\
y \sim \mathrm{EF}(\mu,\phi)</span></p>
<p><span class="math display">f(x) = \beta_0 + \beta_1 x + \textstyle\sum_j \theta_jb_j(x)</span></p>
</div>
</div>
</div>
<div class="fragment">
<ul>
<li>nonlinear generalization of linear <em>mixed-effects</em> models</li>
</ul>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>3: Our study</h1>

</section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title">Data</h2>
<h3>Language models</h3>
<p>Surprisal estimates from</p>
<ul>
<li>Huggingface pretrained GPT2-type models (4 different models), and stat-of-the-art OpenAI GPT3 (3 sizes).</li>
<li>also 5-Gram, LSTM and TransformerXL.</li>
</ul>
<h3>Corpus</h3>
<p>Self-paced reading data from Natural Stories corpus <span class="citation" data-cites="futrell.r:2018">(<a href="#/ref-futrell.r:2018" role="doc-biblioref" onclick="return false;">Futrell et al. 2018</a>)</span>.</p>

<img data-src="pngs/surprisal_densities.png" class="r-stretch"></section>
<section class="slide level2" data-auto-animate="true">
<h2 data-id="quarto-animate-title"></h2>
<h3>Surprisals</h3>
<p><img data-src="pngs/surprisal_means.png" class="absolute" style="top: 10%; left: 0px; width: 60%; "></p>
<p><img data-src="pngs/lms-table.png" class="absolute" style="top: 30%; right: 0px; width: 40%; "></p>
<p><img data-src="pngs/surprisal_densities.png" class="absolute" style="left: 0px; bottom: 12%; width: 60%; "></p>
<!-- 
## Specifying our GAMs {auto-animate=true}

:::: {.columns align=top .onlytextwidth}
::: {.column width="50%"}
**Smooth** effect of surprisal:
```{.R .column code-line-numbers="1|1-2|1-3|1-6" data-id="formula1"}
RT ~ s(surp, bs='tp', k=6) +
     s(subj, surp, bs='fs', m=1) +
     te(freq, len) +
     s(prev_surp, bs='tp') +
     s(subj, prev_surp, bs='fs', m=1) +
     te(prev_freq, prev_len)
```
Main effect:

- TPRS basis: `bs='tp'`, rank `k=6`

By-subject smooths:

- nonlinear factor-smooth interaction `bs='fs'`
- penalty order `m=1`, so null space is just constant functions, penalizes divergence from main smooth

:::
::: {.column width="50%" .fragment}
**Linear** effect of surprisal:
```{.R data-id="formula2" code-line-numbers="1|1-3|1-4|1-7" data-id="formula2"}
RT ~ surp +
     s(subj, bs='re') +
     s(surp, subj, bs='re') +
     te(freq, len) +
     prev_surp +
     s(prev_surp, subj, bs='re') +
     te(prev_freq, prev_len)
```
Main effect

- linear

By-subject linear random effects:

- `s(x,y, bs='re')` $\equiv$ `x:y-1`

:::
:::: -->
<aside class="notes">
<p>Reading time is predicted as a nonlin global effect of surprisal, controlling for subject-related variation, and interactions between log frequency and orthographic length, all for the current word as well as the previous.</p>
<p>Rather than indep by-subj smooths (S&amp;L), we use “factor-smooth interaction”: controls for potentially different nonlinear effects of each participant, sharing same smoothing parameter.</p>
</aside>
</section>
<section class="slide level2 smaller" data-auto-animate="true" data-fig-cap-location="top">
<h2 data-id="quarto-animate-title">Specifying our GAMs</h2>
<div class="columns onlytextwidth" data-align="top">
<div class="column" style="width:50%;">
<p><strong>Smooth</strong> effect of surprisal:</p>
<div class="sourceCode" id="cb1" data-id="formula1"><pre class="sourceCode numberSource R number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>RT <span class="sc">~</span> <span class="fu">s</span>(surp, <span class="at">bs=</span><span class="st">'tp'</span>, <span class="at">k=</span><span class="dv">6</span>) <span class="sc">+</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>     <span class="fu">s</span>(subj, surp, <span class="at">bs=</span><span class="st">'fs'</span>, <span class="at">m=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>     <span class="fu">te</span>(freq, len) <span class="sc">+</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>     <span class="fu">s</span>(prev_surp, <span class="at">bs=</span><span class="st">'tp'</span>) <span class="sc">+</span></span>
<span id="cb1-5"><a href="#cb1-5"></a>     <span class="fu">s</span>(subj, prev_surp, <span class="at">bs=</span><span class="st">'fs'</span>, <span class="at">m=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>     <span class="fu">te</span>(prev_freq, prev_len)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div>
<ul>
<li class="fragment">For nonlinear main effect: <strong>use thin plate regression splines basis (TPRS)</strong>
<ul>
<li class="fragment"><p>better allow us to examine differences in high surprisal area (less data)</p></li>
<li class="fragment"><p>not use high number of basis functions: <strong>limiting the max wiggliness</strong>*</p>
<p>simple question: <em>given a few degrees of freedom, will the GAM use to bend curve upward?</em></p></li>
</ul></li>
<li class="fragment">For by-subject effects: different curve per subject
<ul>
<li class="fragment"><strong>factor-smooth</strong> interaction basis</li>
<li class="fragment"><strong>penalty order <span class="math inline">m=1</span></strong>, so null space is just constant functions, penalizes divergence from main smooth</li>
</ul></li>
<li class="fragment">Likewise effect of previous word</li>
</ul>
</div>
<div class="fragment">
<hr>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="img_external/wilcox.e.2020-fig1.png"></p>
<p></p><figcaption aria-hidden="true">*Cf. <span class="citation" data-cites="wilcox.e:2020">Wilcox et al. (<a href="#/ref-wilcox.e:2020" role="doc-biblioref" onclick="return false;">2020, fig. 1</a>, Natural Stories dataset, largest pretrained models)</span> who use cubic regression basis and a larger value of <span class="math inline">k=20</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div><div class="column" style="width:50%;">
<p><strong>Linear</strong> effect of surprisal:</p>
<div class="sourceCode" id="cb2" data-id="formula2"><pre class="sourceCode numberSource R number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>RT <span class="sc">~</span> surp <span class="sc">+</span> <span class="fu">s</span>(subj, <span class="at">bs=</span><span class="st">'re'</span>) <span class="sc">+</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>     <span class="fu">s</span>(surp, subj, <span class="at">bs=</span><span class="st">'re'</span>) <span class="sc">+</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>     <span class="fu">te</span>(freq, len) <span class="sc">+</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>     prev_surp <span class="sc">+</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>     <span class="fu">s</span>(prev_surp, subj, <span class="at">bs=</span><span class="st">'re'</span>) <span class="sc">+</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>     <span class="fu">te</span>(prev_freq, prev_len)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div>
<ul>
<li class="fragment"><p>Main effect: linear</p></li>
<li class="fragment"><p>By-subject linear random effects: a random slope and intercept per subject (in <code>mgcv</code>, a random <em>linear</em> effect can be obtained with smooth basis <code>s(x,y, bs='re')</code> <span class="math inline">\equiv</span> <code>x:y-1</code>)</p></li>
</ul>
</div>
</div>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>4: Results</h1>

</section>
<section class="slide level2 smaller">
<h2>GAM fits</h2>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">fits</a></li><li><a href="#tabset-3-2">fits diff.</a></li><li><a href="#tabset-3-3">smooth deriv.</a></li><li><a href="#tabset-3-4">lo/hi slope</a></li><li><a href="#tabset-3-5">lo/hi slope diff</a></li><li><a href="#tabset-3-6">EDF</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./pngs/fsm1_k6_wlinear1.png"></p>
<p></p><figcaption aria-hidden="true"><strong>Smooth</strong> effect of surprisal: solid lines. <strong>Linear</strong> effect of surprisal: dashed lines</figcaption><p></p>
</figure>
</div>
</div>
<div id="tabset-3-2">
<p><img data-src="./pngs/fsm1_k6_difflinear1.png"></p>
</div>
<div id="tabset-3-3">
<p><img data-src="./pngs/fsm1_k6.derivatives.png"></p>
</div>
<div id="tabset-3-4">
<p>As a rougher way to look at this: get overall slope of the smooth, in</p>
<ul>
<li><p>high surprisal area (higher half of surprisal values)</p></li>
<li><p>low surprisal area (lower half)</p></li>
</ul>
<p><img data-src="./pngs/fsm1_k6_halflinear_slopes.png"></p>
</div>
<div id="tabset-3-5">
<p>As a rougher way to look at this: get overall slope of the smooth, in</p>
<ul>
<li><p>high surprisal area (higher half of surprisal values)</p></li>
<li><p>low surprisal area (lower half)</p></li>
</ul>
<p>get difference (high slope - low slope).</p>
<p><img data-src="./pngs/fsm1_k6_halflinear_diffs.png" class="absolute" style="height: 60%; "></p>
</div>
<div id="tabset-3-6">
<p><img data-src="./pngs/fsm1_k6_edfs.png" class="absolute" style="height: 60%; "></p>
</div>
</div>
</div>
</section>
<section class="slide level2">
<h2>Difference in fit vs LM quality</h2>
<div class="columns onlytextwidth" data-align="bottom">
<div class="column">
<p><strong>Psyhometric predictive power</strong> Previous literature notes:</p>
<ul>
<li>better LM <span class="math inline">\implies</span> better fit</li>
</ul>
<p>We find possible evidence</p>
<ul>
<li><p>better LMs are more superlinear.</p></li>
<li><p>effect of context not very clear.</p></li>
</ul>
</div><div class="column fragment">
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">v. mean delta loglik</a></li><li><a href="#tabset-4-2">by model</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<p><img data-src="./pngs/linsmooth_delta_loglik1_v_surprisal_means.png"></p>
</div>
<div id="tabset-4-2">
<p><img data-src="./pngs/linsmooth_delta_loglik1.png"></p>
</div>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section class="title-slide slide level1 center">
<h1>5: Conclusion</h1>

</section>
<section class="slide level2">
<h2>Superlinear linking function</h2>
<p>Like previous literature</p>
<ul>
<li>Same dataset often used (TODO: more datasets, different psychometrics)</li>
<li>Use GAMs to examine linking function</li>
</ul>
<p>Different from previous studies</p>
<div class="fragment fade-in-then-semi-out">
<ul>
<li>we used (even) better language models</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>more important: we compare linear and nonlinear fits</li>
<li>we used GAMS to probe a specific question
<ul>
<li>use thin plate regression splines basis</li>
<li>model nonlinear by-subject effects</li>
<li>limited max degrees of freedom in main effect</li>
</ul></li>
</ul>
</div>
<div class="fragment">
<p>Find evidence linearity hypothesis is <em>not</em> justified: linking function is superlinear. Especially for best LMs.</p>
</div>
</section>
<section class="slide level2">
<h2>Questions</h2>
<h4>Why only now?</h4>
<div class="fragment">
<p>Earlier work was good.</p>
<ul>
<li>Have to be using the latest, best, language models, and have to be looking for this.</li>
<li>We have new tools, and we may have to revise our conclusions</li>
</ul>

</div>
<img data-src="img_external/smith.j.2013-fig1.jpg" class="r-stretch quarto-figure-center"><p class="caption"><span class="citation" data-cites="smith.n:2013">Smith and Levy (<a href="#/ref-smith.n:2013" role="doc-biblioref" onclick="return false;">2013, fig. 1</a>)</span></p></section>
<section class="slide level2">
<h2>Questions</h2>
<h4>What does it mean?</h4>
<div class="fragment">
<p>Have a model of human processing? <span class="math inline">\implies</span> should scale superlinearly in surprisal.</p>
</div>
<div class="fragment">
<p>Evidence for sampling-based model?</p>
<ul>
<li>Well, maybe. Shape doesn’t look exponential (unless with even better LMs we see this nonlinearity even more)</li>
</ul>
</div>
<div class="fragment">
<p>Why do older language models look more linear?</p>
</div>
<div class="fragment">
<ul>
<li>Worse language models will overestimate surprisals. Is there structure to this overestimation? What kind of overestimation leads to linking function looking linear?</li>
</ul>

<aside class="notes">
<p>These curves did not look curvy when using ngram models. What could be going on here is systematic overestimation of surprisal by worse models. And the degree of overestimation is possibly <em>structured</em>. How these models were wrong is an important question.</p>
<p>Imagine we select words that are low residual only. Looking at those words, could we color text by how big the residual is? What would we see? Can we use this to assess whether there is pattern in the overestimation of surprisal in worse models?</p>
</aside>
</div>
<img data-src="motivatingGams/gamsRmd-superlinear.gif" class="fragment r-stretch"></section></section>
<section>
<section class="title-slide slide level1 center">
<h1>Thanks!</h1>

</section>
<section class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" style="font-size: 0.85em; column-gap: 5rem; column-count: 2;" role="doc-bibliography">
<div id="ref-aurnhammer.c:2019cogsci" class="csl-entry" role="doc-biblioentry">
Aurnhammer C, Frank SL (2019) <a href="http://hdl.handle.net/2066/213724">Comparing gated and simple recurrent neural network architectures as models of human sentence processing</a>. In: Proceedings of the 41st annual conference of the cognitive science society. pp 112–118
</div>
<div id="ref-balota.d:1985" class="csl-entry" role="doc-biblioentry">
Balota DA, Pollatsek A, Rayner K (1985) The interaction of contextual constraints and parafoveal visual information in reading. Cognitive Psychology 17:364–390. <a href="https://doi.org/10.1016/0010-0285(85)90013-1">https://doi.org/10.1016/0010-0285(85)90013-1</a>
</div>
<div id="ref-boyce.v:2020amlap" class="csl-entry" role="doc-biblioentry">
Boyce V, Levy R (2020) <a href="https://amlap2020.github.io/a/154.pdf"><span class="nocase">A-maze of Natural Stories: Texts are comprehensible using the Maze task</span></a>. In: Malsburg T von der, Vasishth S, Wartenburger I (eds) Proceedings of the 26th architectures and mechanisms for language processing conference (<span>AMLaP 2020</span>). Universit<span>ä</span>t Potsdam, Potsdam, Germany
</div>
<div id="ref-chatterjee.s:2017" class="csl-entry" role="doc-biblioentry">
Chatterjee S, Diaconis P (2017) <a href="https://arxiv.org/abs/1511.01437">The sample size required in importance sampling</a>
</div>
<div id="ref-ehrlich.s:1981" class="csl-entry" role="doc-biblioentry">
Ehrlich SF, Rayner K (1981) Contextual effects on word perception and eye movements during reading. Journal of Memory and Language 20:641. <a href="https://doi.org/10.1016/S0022-5371(81)90220-6">https://doi.org/10.1016/S0022-5371(81)90220-6</a>
</div>
<div id="ref-freer.f:2010" class="csl-entry" role="doc-biblioentry">
Freer CE, Mansinghka VK, Roy DM (2010) <a href="http://citeseerx.ist.psu.edu/viewdoc/versions?doi=10.1.1.187.1495">When are probabilistic programs probably computationally tractable?</a> NIPS Workshop on Monte Carlo Methods for Modern Applications
</div>
<div id="ref-futrell.r:2018" class="csl-entry" role="doc-biblioentry">
Futrell R, Gibson E, Tily HJ, et al (2018) <a href="https://www.aclweb.org/anthology/L18-1012">The <span>Natural Stories</span> corpus</a>. In: Proceedings of the eleventh international conference on language resources and evaluation (<span>LREC</span> 2018). European Language Resources Association (ELRA), Miyazaki, Japan
</div>
<div id="ref-goodkind.a:2018" class="csl-entry" role="doc-biblioentry">
Goodkind A, Bicknell K (2018) <a href="https://doi.org/10.18653/v1/w18-0102">Predictive power of word surprisal for reading times is a linear function of language model quality</a>. In: Proceedings of the 8th workshop on cognitive modeling and computational linguistics (<span>CMCL</span> 2018). Association for Computational Linguistics
</div>
<div id="ref-hale.j:2001" class="csl-entry" role="doc-biblioentry">
Hale J (2001) <a href="https://www.aclweb.org/anthology/N01-1021">A probabilistic <span>E</span>arley parser as a psycholinguistic model</a>. In: Second meeting of the north <span>A</span>merican chapter of the association for computational linguistics
</div>
<div id="ref-levy.r:2005" class="csl-entry" role="doc-biblioentry">
Levy R (2005) <a href="https://www.proquest.com/dissertations-theses/probabilistic-models-word-order-syntactic/docview/305432573/se-2?accountid=12339">Probabilistic models of word order and syntactic discontinuity</a>. PhD thesis, Stanford University
</div>
<div id="ref-levy.r:2008" class="csl-entry" role="doc-biblioentry">
Levy R (2008) Expectation-based syntactic comprehension. Cognition 106:1126–1177. <a href="https://doi.org/10.1016/j.cognition.2007.05.006">https://doi.org/10.1016/j.cognition.2007.05.006</a>
</div>
<div id="ref-meister.c:2021" class="csl-entry" role="doc-biblioentry">
Meister C, Pimentel T, Haller P, et al (2021) <a href="https://arxiv.org/abs/2109.11635">Revisiting the uniform information density hypothesis</a>
</div>
<div id="ref-schijndel.m:2018" class="csl-entry" role="doc-biblioentry">
Schijndel M van, Linzen T (2018) <a href="https://cogsci.mindmodeling.org/2018/papers/0496/">Modeling garden path effects without explicit hierarchical syntax.</a> In: Rogers, Rau, Zhu, Kalish (eds) Proceedings of the annual meeting of the cognitive science society. Madison, Wisconsin
</div>
<div id="ref-smith.n:2013" class="csl-entry" role="doc-biblioentry">
Smith NJ, Levy R (2013) The effect of word predictability on reading time is logarithmic. Cognition 128:302–319. <a href="https://doi.org/10.1016/j.cognition.2013.02.013">https://doi.org/10.1016/j.cognition.2013.02.013</a>
</div>
<div id="ref-wilcox.e:2020" class="csl-entry" role="doc-biblioentry">
Wilcox EG, Gauthier J, Hu J, et al (2020) <a href="https://arxiv.org/abs/2006.01912">On the predictive power of neural language models for human real-time comprehension behavior</a>
</div>
</div>
<div class="footer footer-default">

</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="2022-01-25-MCQLL_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>


  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,

'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,

        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'h.v',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1300,

        height: 1100,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        setTimeout(function() {
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          let href = ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    

</body></html>